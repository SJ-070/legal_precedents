import streamlit as st
import os
import time
import logging
from dotenv import load_dotenv
from utils import (
    
    check_data_files,
    load_data,
    run_parallel_agents,
    run_head_agent,
    get_conversation_history
)

# # --- í™˜ê²½ ë³€ìˆ˜ ë° Gemini API ì„¤ì • ---
# load_dotenv()
# GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
# genai.configure(api_key=GOOGLE_API_KEY)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê´€ì„¸ë²• íŒë¡€ ê¸°ë°˜ ì±—ë´‡",
    page_icon="âš–ï¸",
    layout="wide",
)

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
st.title("âš–ï¸ ê´€ì„¸ë²• íŒë¡€ ê¸°ë°˜ ì±—ë´‡")
st.markdown("ê´€ì„¸ë²• íŒë¡€ ì •ë³´ë¥¼ í™œìš©í•œ AI ê¸°ë°˜ ë²•ë¥  ì±—ë´‡ì…ë‹ˆë‹¤.")


# ëŒ€í™” ê´€ë ¨ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = []

if "processing" not in st.session_state:
    st.session_state.processing = False

# ëŒ€í™” ë§¥ë½ ê´€ë¦¬ ì„¤ì •
if "context_enabled" not in st.session_state:
    st.session_state.context_enabled = True

# ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì„¤ì •
if "loaded_data" not in st.session_state:
    st.session_state.loaded_data = {
        "court_cases": [],
        "tax_cases": [],
        "preprocessed_data": {}
    }

with st.sidebar:
    st.header("ì„¤ì •")
    
    
    # ëŒ€í™” ê´€ë¦¬ ì˜µì…˜ë“¤
    st.header("ëŒ€í™” ê´€ë¦¬")
    
    # ëŒ€í™” ë§¥ë½ í™œìš© ì˜µì…˜
    context_enabled = st.checkbox("ì´ì „ ëŒ€í™” ë§¥ë½ í™œìš©", value=st.session_state.context_enabled)
    if context_enabled != st.session_state.context_enabled:
        st.session_state.context_enabled = context_enabled
        if context_enabled:
            st.success("ì´ì „ ëŒ€í™” ë§¥ë½ì„ í™œìš©í•©ë‹ˆë‹¤.")
        else:
            st.info("ê° ì§ˆë¬¸ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ìµœê·¼ ëŒ€í™” ìœ ì§€ ìˆ˜ ì„ íƒ
    if st.session_state.context_enabled:
        max_history = st.slider("ìµœê·¼ ëŒ€í™” ìœ ì§€ ìˆ˜", min_value=2, max_value=10, value=5)
        st.session_state.max_history = max_history
    
    # ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘ ë²„íŠ¼
    if st.button("ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘í•˜ê¸°"):
        # ë©”ì‹œì§€ ê¸°ë¡ë§Œ ì´ˆê¸°í™” (ë°ì´í„°ëŠ” ìœ ì§€)
        st.session_state.messages = []
        st.session_state.processing = False
        st.success("ìƒˆë¡œìš´ ëŒ€í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‹¤í–‰ ì‹œ ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
has_data_files = check_data_files()
if not has_data_files:
    st.warning("ì¼ë¶€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ í•„ìš”í•œ íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
else:
    # ë°ì´í„°ê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ
    if not st.session_state.loaded_data["court_cases"]:
        with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            court_cases, tax_cases, preprocessed_data = load_data()
            st.session_state.loaded_data = {
                "court_cases": court_cases,
                "tax_cases": tax_cases,
                "preprocessed_data": preprocessed_data
            }
            st.success("ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì €ì¥ëœ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì²˜ë¦¬ ì‹œì‘
    st.session_state.processing = True
    
    # ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        try:
            # ì €ì¥ëœ ë°ì´í„° ì‚¬ìš©
            court_cases = st.session_state.loaded_data["court_cases"]
            tax_cases = st.session_state.loaded_data["tax_cases"]
            preprocessed_data = st.session_state.loaded_data["preprocessed_data"]

            # ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
            conversation_history = ""
            if st.session_state.context_enabled:
                conversation_history = get_conversation_history(
                    max_messages=st.session_state.get('max_history', 5)
                )

            # === [ì„¹ì…˜ 1] ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í‘œì‹œ ===
            progress_display = st.empty()

            # === [ì„¹ì…˜ 2] ì—ì´ì „íŠ¸ ë‹µë³€ ë™ì  í‘œì‹œ (st.status) ===
            agent_status = st.status("ğŸ¤– ì—ì´ì „íŠ¸ ë‹µë³€ ìƒì„± ì¤‘...", expanded=True, state='running')

            # ì—ì´ì „íŠ¸ ì»¨í…Œì´ë„ˆ 6ê°œ ë¯¸ë¦¬ ìƒì„±
            agent_containers = []
            with agent_status:
                for i in range(6):
                    agent_containers.append(st.empty())

            # === [ì„¹ì…˜ 3] ìµœì¢… ë‹µë³€ (ì˜ˆì•½) ===
            final_answer_section = st.empty()

            # === ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰ ë° ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ===
            progress_display.markdown("â³ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")

            # ì œë„ˆë ˆì´í„°ë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬
            agent_responses = []
            completed_count = 0

            for result in run_parallel_agents(
                court_cases, tax_cases, preprocessed_data, prompt, conversation_history
            ):
                # ì—ì´ì „íŠ¸ ì¸ë±ìŠ¤ ì¶”ì¶œ (ì˜ˆ: "Agent 3" -> 2)
                agent_num = int(result['agent'].split()[-1]) - 1

                # ì¦‰ì‹œ UI ì—…ë°ì´íŠ¸
                with agent_containers[agent_num].container():
                    st.subheader(f"ğŸ“‹ {result['agent']}")
                    st.markdown(result['response'])
                    if agent_num < 5:
                        st.divider()

                completed_count += 1
                progress_display.markdown(f"âœ“ {result['agent']} ì™„ë£Œ ({completed_count}/6)")

                agent_responses.append(result)

            # ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ì™„ë£Œ ìˆœì„œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
            agent_responses.sort(key=lambda x: int(x['agent'].split()[-1]))

            # ëª¨ë“  ì—ì´ì „íŠ¸ ì™„ë£Œ
            progress_display.markdown("âœ“ ëª¨ë“  ì—ì´ì „íŠ¸ ì™„ë£Œ | â³ ìµœì¢… ë‹µë³€ í†µí•© ì¤‘...")

            # === Head Agentë¡œ ìµœì¢… ì‘ë‹µ ìƒì„± ===
            head_response = run_head_agent(
                agent_responses, prompt, conversation_history
            )

            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if isinstance(head_response, dict):
                final_response = head_response.get("response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                final_response = head_response

            # === [ì„¹ì…˜ 2] ìë™ìœ¼ë¡œ ë‹«ê¸° ===
            agent_status.update(
                label="ğŸ¤– ê° ì—ì´ì „íŠ¸ ë‹µë³€ ë³´ê¸°",
                state="complete",
                expanded=False
            )

            # === [ì„¹ì…˜ 1] ì™„ë£Œ ìƒíƒœ ===
            progress_display.markdown("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")
            time.sleep(0.3)
            progress_display.empty()

            # === [ì„¹ì…˜ 3] ìµœì¢… ë‹µë³€ í‘œì‹œ ===
            with final_answer_section.container():
                st.markdown("### ğŸ“Œ ìµœì¢… ë‹µë³€")
                st.markdown(final_response)

            # ì‘ë‹µ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": final_response})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logging.error(f"ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ì €ì¥
            error_message = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.session_state.messages.append({"role": "assistant", "content": error_message})
    
    # ì²˜ë¦¬ ì™„ë£Œ
    st.session_state.processing = False

# ì‚¬ì´ë“œë°”ì— ì‚¬ìš© ì˜ˆì‹œ ë° ì •ë³´ ì¶”ê°€
with st.sidebar:
    st.subheader("í”„ë¡œì íŠ¸ ì •ë³´")
    st.markdown("""
    ì´ ì±—ë´‡ì€ ê´€ì„¸ë²• íŒë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

    **ë°ì´í„° ì†ŒìŠ¤**
    - KCS íŒë¡€: 423ê±´
    - MOLEG íŒë¡€: 486ê±´
    - ì´ 909ê±´ì˜ íŒë¡€ ë°ì´í„°

    **ì‹œìŠ¤í…œ êµ¬ì¡°**
    - 6ê°œì˜ AI ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
    - Google Gemini 2.5 Flash ëª¨ë¸ ì‚¬ìš©
    - Character n-gram TF-IDF ê²€ìƒ‰
    - Multi-Agent í†µí•© ë‹µë³€ ìƒì„±

    **ì£¼ìš” ì¥ì **
    - ì™„ì „ ë¬´ë£Œ (Gemini API ë¬´ë£Œ í‹°ì–´)
    - ì¼ë°˜ ë…¸íŠ¸ë¶/ë¬´ë£Œ Streamlit Cloud êµ¬ë™
    - ë¹ ë¥¸ ì‘ë‹µ (ê²€ìƒ‰ 0.05ì´ˆ, ë‹µë³€ 5-10ì´ˆ)
    """)